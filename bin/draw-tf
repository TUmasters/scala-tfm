#!/usr/bin/env python3


## CLI

import os, sys, shutil, argparse
import random, math

parser = argparse.ArgumentParser(description='Parses a series of text documents into a better format.')
parser.add_argument('data_path', type=str, metavar='D', help='data folder.')
parser.add_argument('model', type=str, metavar='D', help='topic flow model.')
args = parser.parse_args()


## Load documents

data_path = args.data_path.rstrip('/')
model_path = data_path + '/' + args.model

raw_file = data_path + '/raw.json'
data_file = data_path + '/documents.json'
document_topics_file = model_path + '/' + 'document-topics.json'
word_topics_file = model_path + '/' + 'word-topics.json'
model_params_file = model_path + '/' + 'params.json'

## Construct conversation tree

from _document import parse_corpus, find_roots, prune
import json
import numpy as np

document_raw = json.load(open(raw_file, 'r'))
document_data = {data['id']:data for data in json.load(open(data_file, 'r'))}
document_topics = json.load(open(document_topics_file, 'r'))
word_topics = json.load(open(word_topics_file, 'r'))
model_params = json.load(open(model_params_file, 'r'))
# a = np.loadtxt(model_path + '/a.mat', delimiter=',')
# pi = np.loadtxt(model_path + '/pi.mat', delimiter=',')

num_topics = model_params['num-topics']
num_words = model_params['num-words']

corpus = parse_corpus(document_raw)

to_prune = [d for d in corpus if not d.id in document_topics.keys()]

corpus = prune(corpus, to_prune)

roots = find_roots(corpus)
roots = [root for root in roots if root.size >= 3]

d_topic = {key:max(values, key=lambda x: x['p'])['topic']
           for key, values in document_topics.items()}
d_topic_p = {key:next(x['p'] for x in values if x['topic'] == d_topic[key])
             for key, values in document_topics.items()}

## Calculate word weights

words = set(word_topics.keys())
word2idx = {word:idx for idx, word in enumerate(words)}
word_weights = np.zeros((num_words, num_topics))
word_freq = {word:0 for word in words}

for data in document_data.values():
    for word in set(data['words']):
        word_freq[word] += 1


for word, topics in word_topics.items():
    i = word2idx[word]
    row = np.array([t['p'] for t in sorted(topics, key=lambda x: x['topic'])])
    # if word_freq[word] > 20:
    word_weights[i,:] = (row / sum(row))

## HTML Templates

from string import Template

main_template = Template(open('_templates/main.html').read())
word_block_template = Template(open('_templates/word-block.html').read())
document_block_template = Template(open('_templates/document-block.html').read())
topic_style_template = Template("--topic-${topic}: #${color};\n")


## Color styles of each topic

# https://stackoverflow.com/a/876872
def colors(n):
    import colorsys
    colors = []
    hsv_tuples = [(x*0.9/n, 0.7, 0.7) for x in range(n)]
    rgb_tuples = [[int(x * 255) for x in colorsys.hsv_to_rgb(*hsv)]
                   for hsv in hsv_tuples]
    for rgb in rgb_tuples:
        html = ''.join(["{:02x}".format(x) for x in rgb])
        colors += [html]
    return colors


topic_colors = colors(num_topics)
topic_style = """:root {\n
--topic-null: #000;
"""
for topic_id in range(num_topics):
    topic_style += topic_style_template.substitute({
        'topic': topic_id,
        'color': topic_colors[topic_id]
    })
topic_style += "}\n"


topic_nav = ""
for topic_id in range(num_topics):
    topic_nav += '<a href="topic-{0}.html" style="width: {1}%; background-color:var(--topic-{0})">{0}</a>'.format(
        topic_id,
        100./num_topics
    )


def topic_words(topic_id):
    html = '<h1>words</h1><br /><div class="content">'

    weights = {word:word_weights[word2idx[word], topic_id] for word in words}
    max_weight = max(weights.values())
    word_data = []
    for word in words:
        word_html = word_block_template.substitute({
            'word': word,
            'weight': max(weights[word] / max_weight, 0.25)
        })
        word_data += [(word_html, weights[word])]
    sorted_words = sorted(word_data, key=lambda x:-x[1])[:100]
    word_html = ' '.join([w[0] for w in sorted_words])
    html += word_html
    html += "</div>"
    return html


def transition_stats(title, probs):
    probs = sorted(enumerate(probs * 100), key=lambda x: -x[1])
    html = '<p><b>{}</b>\n'.format(title)
    for t2, p2 in probs:
        html += """<a href="topic-{0}.html" class="topic" style="border-color: var(--topic-{0});">
  <span>Topic {0} ({1:.4f}%)</span></a>""".format(t2, p2)
    html += '</p>'
    return html

def topic_stats(topic_id):
    html = '<h1>stats</h1><br /><div class="content">'
    # in_probs = a[:, topic_id]
    # out_probs = a[topic_id, :]
    # in_degree = sum(in_probs)
    # html += '<p><b>entrance probability</b> {:.4f}</p>'.format(pi[topic_id])
    # html += '<p><b>weighted in-degree</b> {:.4f}</p>'.format(in_degree)
    # html += transition_stats('parent probabilities', in_probs)
    # html += transition_stats('response probabilities', out_probs)
    html += '</div>'
    return html


def sample_documents(topic_id):
    html = '<h1>documents</h1><br /><div class="content">'
    SAMPLE_SIZE = 100
    new_corpus = [document for document in corpus if d_topic[document.id] == topic_id]
    if len(new_corpus) > SAMPLE_SIZE:
        new_corpus = random.sample(new_corpus, SAMPLE_SIZE)
    for document in new_corpus:
        if document.parent:
            html += document_html(document.parent, topic_id, root=True, depth=2, child=document)
        else:
            html += document_html(document, topic_id, root=True, depth=1)
    html += '</div>'
    return html


def sample_conversations(topic_id):
    html = '<h1>conversations</h1><br /><div class="content">'
    SAMPLE_SIZE = 50
    documents_with_topic = set([d.id for d in corpus if d_topic[d.id] == topic_id])
    new_roots = [root for root in roots
                if not set(root.flatten_ids()).isdisjoint(documents_with_topic)]
    if len(new_roots) > SAMPLE_SIZE:
        new_roots = random.sample(new_roots, SAMPLE_SIZE)
    for root in new_roots:
        html += document_html(root, topic_id, root=True)
    html += '</div>'
    return html


def document_html(document, main_topic_id, root=False, child=None, depth=float('inf')):
    if document.id in d_topic:
        topic = d_topic[document.id]
        topic_p = "{:.2f}".format(d_topic_p[document.id] * 98)
        tokens = document_data[document.id]['words']
        tokens = ' '.join('<span style="font-size: {1:.4f};">[{0}]</span>'\
                          .format(token, max(word_weights[word2idx[token], topic]*128, 8), topic)
                          for token in tokens)
    else:
        topic = 'null'
        topic_p = 0
        tokens = ' '.join('[<span>{}</span>]'.format(token) for token in tokens)
    replies = ''
    if child:
        replies = document_html(child, main_topic_id, depth=depth-1)
    elif depth > 0:
        replies = ''.join([document_html(reply, main_topic_id, depth=depth-1)
                           for reply in document.replies])
    return document_block_template.substitute({
        'root': 'root' if root else '',
        'main_topic': 'main-topic' if topic == main_topic_id else '',
        'topic': topic,
        'topic_p': topic_p,
        'author': document.author,
        'content': document.content,
        'tokens': tokens,
        'replies': replies
    })


web_path = model_path + '/web'
if os.path.exists(web_path):
    shutil.rmtree(web_path)
os.makedirs(web_path)


for topic_id in range(num_topics):
    html = main_template.substitute({
        'topic': topic_id,
        'topic_style': topic_style,
        'topic_nav': topic_nav,
        'topic_words': topic_words(topic_id),
        'topic_stats': topic_stats(topic_id),
        'sample_conversations': sample_documents(topic_id) + sample_conversations(topic_id)
    })
    topic_filename = web_path + '/topic-' + str(topic_id) + '.html'
    with open(topic_filename, 'w') as f:
        f.write(html)
        print("Wrote {}.".format(topic_filename))


def word_query():
    while True:
        word = input("word: ")
        if not word in word2idx:
            print(" invalid word!")
            continue
        probs = sorted(enumerate(word_weights[word2idx[word], :]), key=lambda x: -x[1])
        for topic, prob in probs:
            if prob >= 5e-3:
                print(" Topic {0}: {1:.2f}%".format(topic, prob*100))

word_query()
