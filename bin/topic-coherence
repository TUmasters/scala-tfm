#!/usr/bin/env python3

import os, json, argparse
import math
import numpy as np
from statistics import mean, median
from _document import parse_corpus
import urllib.request, urllib.parse


def load_corpus(corpus_file, unstemmer=None):
    print('Loading...')
    if not os.path.exists(corpus_file):
        print("Could not find file '{}'.".format(corpus_file))
        return
    with open(corpus_file, 'r') as f:
        data = json.load(f)

    for item in data:
        item['reply_to'] = item['parent']
        item['parent'] = None

    corpus = parse_corpus(data)

    if unstemmer:
        for doc in corpus:
            doc.words = [unstemmer[word] for word in doc.words]

    return corpus


parser = argparse.ArgumentParser(description='Translates corpus into format that can be used by the Biterm Topic Model.')
parser.add_argument('corpus_file', type=str, metavar='D', help='file with documents.')
parser.add_argument('model', type=str, help='directory of trained model')
args = parser.parse_args()

data_dir = os.path.dirname(args.corpus_file)
model_dir = data_dir + '/' + args.model

with open(data_dir + '/stem.json', 'r') as f:
    unstemmer = json.load(f)


corpus = load_corpus(args.corpus_file, unstemmer)

corpus = [doc for doc in corpus if len(doc.words) > 0]


def palmetto(words, method='umass', base_url='http://localhost:7777'):
    words = [urllib.parse.quote_plus(word) for word in words]
    url = base_url + '/service/{}?words={}'.format(method, '+'.join(words))
    response = urllib.request.urlopen(url)
    score = float(response.read())
    return score


def topic_coherence(model_dir):
    print(model_dir)
    with open(model_dir + '/params.json', 'r') as f:
        params = json.load(f)

    with open(model_dir + '/word-topics.json', 'r') as f:
        word_topics = json.load(f)

    topic_words = {k:[] for k in range(params['num-topics'])}

    for word, topics in word_topics.items():
        word = unstemmer[word]
        for topic_data in topics:
            k = topic_data['topic']
            p = topic_data['p']
            topic_words[k] += [(word, p)]

    top_k = 10
    top_words = {}
    for k in range(params['num-topics']):
        top_words[k] = [w[0] for w in sorted(topic_words[k], key=lambda x: -x[1])[:top_k]]

    scores = []
    for k in range(params['num-topics']):
        score = palmetto(top_words[k])
        print('{:2d}  {:6.2f}  '.format(k, score) + ', '.join(top_words[k]))
        scores += [score]
    return np.median(scores)


scores = []
for trial in range(0, 10):
    trial_dir = model_dir + '/new-trial{:02d}'.format(trial)
    scores += [topic_coherence(trial_dir)]

score_cols = ["{:2.5f}".format(score) for score in scores]
print("{:2.8f}  {}".format(np.mean(scores), '  '.join(score_cols)))
